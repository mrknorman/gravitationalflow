{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5: Composing Examples\n",
    "\n",
    "In this notebook we will examine how we can use the elements we have encountered so far, in order to construct a examples which will allow us to train machine learning models with data generated in real time. This is a core functionality of GravyFlow.\n",
    "\n",
    "As usual, we begin by performing the relevent imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in imports\n",
    "from typing import List, Dict, Iterator\n",
    "from pathlib import Path\n",
    "\n",
    "# Dependency imports: \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "# Import the GravyFlow module.\n",
    "import gravyflow as gf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an example generator through composition\n",
    "\n",
    "We can combine all the elements we have seen so, noise generation, waveform generation, and waveform projection, and use MLy to create a custom Python generator.\n",
    "\n",
    "In order to scale the injection with respect to the noise we can use a `gf.ScalingMethod` object. GravyFlow supports scaling with SNR (`gf.ScalingTypes.SNR`), HRSS (`gf.ScalingTypes.HRSS`), and HPEAK (`gf.ScalingTypes.HPEAK`).\n",
    "\n",
    "- `value` : `Union[gf.Distribution, np.ndarray]`, Required\n",
    "  > The value or distribution to use to scale the injections, units vary depending on type parameter.\n",
    "\n",
    "- `type_` : `gf.ScalingTypes`, Required\n",
    "  > Type of scaling, one of either `gf.ScalingTypes.SNR`, `gf.ScalingTypes.HRSS`, or `gf.ScalingTypes.HPEAK`.\n",
    "\n",
    "Let us create a `gf.ScalingMethod` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scaling method object in order to scale the injection to the noise:\n",
    "scaling_method : gf.ScalingMethod = gf.ScalingMethod(\n",
    "    value=gf.Distribution(\n",
    "        value=20,\n",
    "        type_=gf.DistributionType.CONSTANT\n",
    "    ),\n",
    "    type_=gf.ScalingTypes.SNR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can set up all the other elements that we can use to compose or example generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 10:56:54,533 - INFO - Available GPUs: ['5']\n",
      "2025-02-11 10:56:54,535 - INFO - Visible GPUs after restriction: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]\n",
      "2025-02-11 10:56:54,569 - INFO - Recomputing valid segments!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 10:56:55,046 - INFO - Loading event times from cache.\n"
     ]
    }
   ],
   "source": [
    "with gf.env():\n",
    "    # This object will be used to obtain real interferometer data based on specified parameters.\n",
    "    ifo_data_obtainer : gf.IFODataObtainer = gf.IFODataObtainer(\n",
    "        observing_runs=gf.ObservingRun.O3, # Specify the observing run (e.g., O3).\n",
    "        data_quality=gf.DataQuality.BEST,  # Choose the quality of the data (e.g., BEST).\n",
    "        data_labels=[                      # Define the types of data to include.\n",
    "            gf.DataLabel.NOISE, \n",
    "            gf.DataLabel.GLITCHES\n",
    "        ],\n",
    "        segment_order=gf.SegmentOrder.RANDOM, # Order of segment retrieval (e.g., RANDOM).\n",
    "        force_acquisition=True,               # Force the acquisition of new data.\n",
    "        cache_segments=False                  # Choose not to cache the segments.\n",
    "    )\n",
    "\n",
    "    # Initialize the noise generator wrapper:\n",
    "    # This wrapper will use the ifo_data_obtainer to generate real noise based on the specified parameters.\n",
    "    noise: gf.NoiseObtainer = gf.NoiseObtainer(\n",
    "        ifo_data_obtainer=ifo_data_obtainer, # Use the previously set up IFODataObtainer object.\n",
    "        noise_type=gf.NoiseType.REAL,        # Specify the type of noise as REAL.\n",
    "        ifos=gf.IFO.L1 # Specify the interferometer (e.g., LIGO Livingston L1).\n",
    "    )\n",
    "\n",
    "    # Define a uniform distribution for the mass of the first object in solar masses.\n",
    "    mass_1_distribution_msun : gf.Distribution = gf.Distribution(\n",
    "        min_=10.0, \n",
    "        max_=60.0, \n",
    "        type_=gf.DistributionType.UNIFORM\n",
    "    )\n",
    "\n",
    "    # Define a uniform distribution for the mass of the second object in solar masses.\n",
    "    mass_2_distribution_msun : gf.Distribution = gf.Distribution(\n",
    "        min_=10.0, \n",
    "        max_=60.0, \n",
    "        type_=gf.DistributionType.UNIFORM\n",
    "    )\n",
    "\n",
    "    # Define a uniform distribution for the inclination of the binary system in radians.\n",
    "    inclination_distribution_radians : gf.Distribution = gf.Distribution(\n",
    "        min_=0.0, \n",
    "        max_=np.pi, \n",
    "        type_=gf.DistributionType.UNIFORM\n",
    "    )\n",
    "\n",
    "    # Initialize a PhenomD waveform generator with the defined distributions.\n",
    "    # This generator will produce waveforms with randomly varied masses and inclination angles.\n",
    "    phenom_d_generator : gf.WaveformGenerator = gf.cuPhenomDGenerator(\n",
    "        mass_1_msun=mass_1_distribution_msun,\n",
    "        mass_2_msun=mass_2_distribution_msun,\n",
    "        inclination_radians=inclination_distribution_radians,\n",
    "        scaling_method=scaling_method,\n",
    "        injection_chance=0.5 # Set so half produced examples will not contain this signal\n",
    "    )\n",
    "    \n",
    "    generator : Iterator = gf.data(       \n",
    "        noise_obtainer=noise,\n",
    "        waveform_generators=phenom_d_generator,\n",
    "        num_examples_per_batch=8,\n",
    "        input_variables=[\n",
    "            gf.ReturnVariables.WHITENED_ONSOURCE, \n",
    "        ],\n",
    "        output_variables=[\n",
    "            gf.ReturnVariables.INJECTIONS, \n",
    "            gf.ReturnVariables.WHITENED_INJECTIONS,\n",
    "            gf.ReturnVariables.INJECTION_MASKS\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similiarly to the individual elements, we can use this example generator as an iterator, and produce N examples for use to examine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 10:56:56,196 - INFO - Available GPUs: ['5']\n",
      "2025-02-11 10:56:56,200 - INFO - Visible GPUs after restriction: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "with gf.env():\n",
    "    # Generate a batch of examples using the composed generator.\n",
    "    input_data, output_data = next(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the output of the generator to examine its format, which values are returned will depend on which parameters we have requested in the input_variables, and output_variables field in our gf.data function. Both are returned in the form of a dictionary, which can easly be fed into a keras model if the inputs of the model are named similarly to the variable feilds, we will show an example of this later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary to feed the model: \n",
      " {'WHITENED_ONSOURCE': <tf.Tensor: shape=(8, 1, 2048), dtype=float16, numpy=\n",
      "array([[[ 1.84  , -0.576 , -0.5933, ..., -0.3196, -0.3562,\n",
      "         -0.7817]],\n",
      "\n",
      "       [[ 1.042 ,  1.724 ,  0.738 , ..., -0.456 , -1.083 ,\n",
      "          1.209 ]],\n",
      "\n",
      "       [[ 1.011 ,  0.859 , -0.1366, ...,  1.289 ,  0.6846,\n",
      "          0.2737]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.1262, -0.49  , -0.6177, ...,  0.7026, -2.033 ,\n",
      "         -0.8545]],\n",
      "\n",
      "       [[ 0.6216, -1.045 , -1.036 , ..., -0.4414,  1.321 ,\n",
      "         -0.8643]],\n",
      "\n",
      "       [[ 0.5684,  1.71  , -1.056 , ...,  1.073 , -0.955 ,\n",
      "         -0.3467]]], dtype=float16)>}\n",
      "Dictionary to use as the model labels: \n",
      " {'INJECTIONS': <tf.Tensor: shape=(8, 1, 2048), dtype=float32, numpy=\n",
      "array([[[ 0.21530649,  0.22814944,  0.23822331, ...,\n",
      "          0.        ,  0.        ,  0.        ]],\n",
      "\n",
      "       [[ 0.        ,  0.        ,  0.        , ...,\n",
      "          0.        ,  0.        ,  0.        ]],\n",
      "\n",
      "       [[ 0.        ,  0.        ,  0.        , ...,\n",
      "          0.        ,  0.        ,  0.        ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.11483847, -0.12659098, -0.13749549, ...,\n",
      "          0.        ,  0.        ,  0.        ]],\n",
      "\n",
      "       [[ 0.        ,  0.        ,  0.        , ...,\n",
      "          0.        ,  0.        ,  0.        ]],\n",
      "\n",
      "       [[ 0.        ,  0.        ,  0.        , ...,\n",
      "          0.        ,  0.        ,  0.        ]]], dtype=float32)>, 'WHITENED_INJECTIONS': <tf.Tensor: shape=(8, 8, 1, 2048), dtype=float32, numpy=\n",
      "array([[[[-5.07596415e-03, -5.01008332e-03, -5.04888594e-03,\n",
      "          ..., -1.49048009e-08, -5.21668042e-08,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        [[-1.56675428e-02, -1.57755427e-02, -1.56395398e-02,\n",
      "          ...,  1.49048009e-08, -7.45240047e-09,\n",
      "           5.96192038e-08]],\n",
      "\n",
      "        [[-6.33310061e-03, -6.86455239e-03, -7.08561065e-03,\n",
      "          ..., -1.49048009e-08, -2.23572023e-08,\n",
      "          -2.23572023e-08]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.37559678e-02, -1.44939795e-02, -1.46558238e-02,\n",
      "          ..., -7.45240047e-09,  1.49048009e-08,\n",
      "           1.49048009e-08]],\n",
      "\n",
      "        [[-4.36638948e-03, -3.16776405e-03, -1.44026068e-03,\n",
      "          ..., -7.45240047e-09, -5.21668042e-08,\n",
      "          -2.23572023e-08]],\n",
      "\n",
      "        [[-1.48655130e-02, -1.39437728e-02, -1.23813488e-02,\n",
      "          ...,  1.49048009e-08,  7.45240047e-09,\n",
      "           4.47144046e-08]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 2.08560238e-03,  2.03023409e-03,  1.95603794e-03,\n",
      "          ..., -3.68941529e-03, -1.95884868e-03,\n",
      "          -2.46242213e-04]],\n",
      "\n",
      "        [[-4.76905843e-03, -4.36330959e-03, -3.91589478e-03,\n",
      "          ..., -2.32788408e-03, -2.89100967e-03,\n",
      "          -3.51962703e-03]],\n",
      "\n",
      "        [[ 3.75041272e-03,  3.72491032e-03,  3.66971758e-03,\n",
      "          ..., -1.04545997e-02, -1.04199238e-02,\n",
      "          -9.03825648e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.04926061e-03, -1.38146896e-03, -1.70873734e-03,\n",
      "          ..., -1.00106904e-02, -9.35028866e-03,\n",
      "          -8.16982053e-03]],\n",
      "\n",
      "        [[-9.78775905e-04, -8.37863830e-04, -6.92748232e-04,\n",
      "          ..., -1.13533149e-02, -9.78580676e-03,\n",
      "          -7.77116185e-03]],\n",
      "\n",
      "        [[ 7.62628508e-04,  5.11191553e-04,  2.50882789e-04,\n",
      "          ..., -7.64370337e-03, -6.64230948e-03,\n",
      "          -4.92467312e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]],\n",
      "\n",
      "        [[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
      "          ...,  0.00000000e+00,  0.00000000e+00,\n",
      "           0.00000000e+00]]]], dtype=float32)>, 'INJECTION_MASKS': <tf.Tensor: shape=(1, 8), dtype=float32, numpy=array([[1., 0., 0., 0., 1., 1., 0., 0.]], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "# This is the data we will uses as an input examples to out model:\n",
    "print(f\"Dictionary to feed the model: \\n {input_data}\")\n",
    "\n",
    "# This is the target data we will use as labels to train our model:\n",
    "print(f\"Dictionary to use as the model labels: \\n {output_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then print some examples from this dataset to examine the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1.84   -0.576  -0.5933 ... -0.3196 -0.3562 -0.7817]]\n",
      "\n",
      " [[ 1.042   1.724   0.738  ... -0.456  -1.083   1.209 ]]\n",
      "\n",
      " [[ 1.011   0.859  -0.1366 ...  1.289   0.6846  0.2737]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.1262 -0.49   -0.6177 ...  0.7026 -2.033  -0.8545]]\n",
      "\n",
      " [[ 0.6216 -1.045  -1.036  ... -0.4414  1.321  -0.8643]]\n",
      "\n",
      " [[ 0.5684  1.71   -1.056  ...  1.073  -0.955  -0.3467]]], shape=(8, 1, 2048), dtype=float16)\n",
      "tf.Tensor(\n",
      "[[0.21530649 0.22814944 0.23822331 ... 0.         0.\n",
      "  0.        ]], shape=(1, 2048), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The value for key 'Injection' is not an np.ndarray.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 22\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Iterate over the multi-injections and their corresponding parameters.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m onsource_, injection, whitened_injection, masks_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m     15\u001b[0m         onsource,\n\u001b[1;32m     16\u001b[0m         injections,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     ):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Create strain plots for each Phenom D and WNB injection with titles displaying the parameter values.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     generated_data_layout\u001b[38;5;241m.\u001b[39mappend([\n\u001b[0;32m---> 22\u001b[0m         gf\u001b[38;5;241m.\u001b[39mgenerate_strain_plot(\n\u001b[1;32m     23\u001b[0m             {\n\u001b[1;32m     24\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnsouce\u001b[39m\u001b[38;5;124m\"\u001b[39m: onsource_,\n\u001b[1;32m     25\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhitened Injection\u001b[39m\u001b[38;5;124m\"\u001b[39m: whitened_injection,\n\u001b[1;32m     26\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInjection\u001b[39m\u001b[38;5;124m\"\u001b[39m: injection,\n\u001b[1;32m     27\u001b[0m             },\n\u001b[1;32m     28\u001b[0m             height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m,\n\u001b[1;32m     29\u001b[0m             width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m,\n\u001b[1;32m     30\u001b[0m             title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExample Output. Has Injection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mbool\u001b[39m(masks_)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m         )\n\u001b[1;32m     32\u001b[0m     ])\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Arrange the plots in a grid layout and display them in the notebook.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m grid \u001b[38;5;241m=\u001b[39m gridplot(generated_data_layout)\n",
      "File \u001b[0;32m~/gravyflow/gravyflow/src/utils/plotting.py:147\u001b[0m, in \u001b[0;36mgenerate_strain_plot\u001b[0;34m(strain, sample_rate_hertz, title, colors, has_legend, scale_factor, height, width)\u001b[0m\n\u001b[1;32m    144\u001b[0m         curr_strain[key] \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Get num samples and check dictionaries:\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m num_samples \u001b[38;5;241m=\u001b[39m check_ndarrays_same_length(curr_strain)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Generate time axis for plotting:\u001b[39;00m\n\u001b[1;32m    150\u001b[0m time_axis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.0\u001b[39m, duration_seconds, num_samples)\n",
      "File \u001b[0;32m~/gravyflow/gravyflow/src/utils/plotting.py:77\u001b[0m, in \u001b[0;36mcheck_ndarrays_same_length\u001b[0;34m(my_dict)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m my_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;66;03m# Check if the value is an np.ndarray:\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(value, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, tf\u001b[38;5;241m.\u001b[39mTensor)):\n\u001b[0;32m---> 77\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe value for key \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not an np.ndarray.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# Check the length of the ndarray:\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     current_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value)\n",
      "\u001b[0;31mValueError\u001b[0m: The value for key 'Injection' is not an np.ndarray."
     ]
    }
   ],
   "source": [
    "# Extract the data from the generator output: \n",
    "onsource: tf.Tensor = input_data[gf.ReturnVariables.WHITENED_ONSOURCE.name]\n",
    "injections: tf.Tensor = output_data[gf.ReturnVariables.INJECTIONS.name][0]\n",
    "whitened_injections: tf.Tensor = output_data[gf.ReturnVariables.WHITENED_INJECTIONS.name][0]\n",
    "injection_masks: tf.Tensor = output_data[gf.ReturnVariables.INJECTION_MASKS.name][0]\n",
    "\n",
    "print(onsource)\n",
    "print(injections)\n",
    "\n",
    "# Initialize an empty layout for the strain plots.\n",
    "generated_data_layout: List = []\n",
    "\n",
    "# Iterate over the multi-injections and their corresponding parameters.\n",
    "for onsource_, injection, whitened_injection, masks_ in zip(\n",
    "        onsource,\n",
    "        injections,\n",
    "        whitened_injections,\n",
    "        injection_masks\n",
    "    ):\n",
    "    # Create strain plots for each Phenom D and WNB injection with titles displaying the parameter values.\n",
    "    generated_data_layout.append([\n",
    "        gf.generate_strain_plot(\n",
    "            {\n",
    "                \"Onsouce\": onsource_,\n",
    "                \"Whitened Injection\": whitened_injection,\n",
    "                \"Injection\": injection,\n",
    "            },\n",
    "            height=400,\n",
    "            width=800,\n",
    "            title=f\"Example Output. Has Injection: {bool(masks_)}\"\n",
    "        )\n",
    "    ])\n",
    "\n",
    "# Arrange the plots in a grid layout and display them in the notebook.\n",
    "grid = gridplot(generated_data_layout)\n",
    "output_notebook()\n",
    "show(grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gravyflow2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
