{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a model with a GravyFlow Dataset\n",
    "\n",
    "In this notebook we will use our generated dataset to train a keras model. We start with the needed imports: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 17:36:34.010315: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Built-in imports\n",
    "from typing import List, Dict\n",
    "from pathlib import Path\n",
    "\n",
    "# Dependency imports: \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Dense, Flatten, Dropout, ELU\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Import the GravyFlow module.\n",
    "import gravyflow as gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:TensorFlow version: 2.12.1, CUDA version: 11.8\n",
      "2024-07-03 17:37:02.627588: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-07-03 17:37:02.627668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3000 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:07:00.0, compute capability: 7.0\n",
      "INFO:root:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Set up the environment using gf.env() and return a tf.distribute.Strategy object.\n",
    "env : tf.distribute.Strategy = gf.env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a TensorFlow dataset through composition:\n",
    "\n",
    "Rather than generating a generic Python iterator, we can also use GravyFlow to create a custom TensorFlow dataset. This will give us the ability to utalise all the functionality provided by the TensorFlow dataset class, including seamless integration with keras models, whilst maintaining the ability to generate datasets quickly enough for real time training, only caching downloaded data segments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will create a keras model, inspired by a model from the literature, found at Gabbard _et at._ here: https://link.aps.org/doi/10.1103/PhysRevLett.120.141103:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gabbard(\n",
    "        input_shape_onsource : int, \n",
    "        input_shape_offsource : int\n",
    "    ) -> tf.keras.Model:\n",
    "    \n",
    "    # Define the inputs based on the dictionary keys and expected shapes\n",
    "    # Replace `input_shape_onsource` and `input_shape_offsource` with the actual shapes\n",
    "    onsource_input = Input(shape=input_shape_onsource, name=\"ONSOURCE\")\n",
    "    offsource_input = Input(shape=input_shape_offsource, name=\"OFFSOURCE\")\n",
    "\n",
    "    # Pass the inputs to your custom Whiten layer\n",
    "    # Assuming your Whiten layer can handle multiple inputs\n",
    "    whiten_output = gf.Whiten()([onsource_input, offsource_input])\n",
    "\n",
    "    x = gf.Reshape()(whiten_output)\n",
    "    \n",
    "    # Convolutional and Pooling layers\n",
    "    x = Conv1D(8, 64, padding='same', name=\"Convolutional_1\")(x)\n",
    "    x = ELU(name=\"ELU_1\")(x)\n",
    "    x = MaxPooling1D(pool_size=4, strides=4, name=\"Pooling_1\", padding=\"same\")(x)\n",
    "    \n",
    "    x = Conv1D(8, 32, padding='same', name=\"Convolutional_2\")(x)\n",
    "    x = ELU(name=\"ELU_2\")(x)\n",
    "    x = Conv1D(16, 32, padding='same', name=\"Convolutional_3\")(x)\n",
    "    x = ELU(name=\"ELU_3\")(x)\n",
    "    x = MaxPooling1D(pool_size=4, strides=4, name=\"Pooling_3\", padding=\"same\")(x)\n",
    "    \n",
    "    # Flatten layer\n",
    "    x = Flatten(name=\"Flatten\")(x)\n",
    "    \n",
    "    # Dense layers with dropout\n",
    "    x = Dense(64, name=\"Dense_1\")(x)\n",
    "    x = ELU(name=\"ELU_7\")(x)\n",
    "    x = Dropout(0.5, name=\"Dropout_1\")(x)\n",
    "    \n",
    "    x = Dense(64, name=\"Dense_2\")(x)\n",
    "    x = ELU(name=\"ELU_8\")(x)\n",
    "    x = Dropout(0.5, name=\"Dropout_2\")(x)\n",
    "    \n",
    "    outputs = Dense(1, activation='sigmoid', name=\"INJECTION_MASKS\")(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=[onsource_input, offsource_input], outputs=outputs, name=\"custom\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are only using one injection, we expect our output label to be a single value for each example, therefore we must adjust the dimensionality of the injection masks output with tensorflow datasets mapping functionality, we define the function we want to map to the dataset here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_features(features, labels):\n",
    "    labels['INJECTION_MASKS'] = labels['INJECTION_MASKS'][0]\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow and keras requires that the model and training dataset are created in the same scope, and is quite strict about these limitations. Thus we will here create our dataset and our model in the same scope. Nominally, it is anticipated that GravyFlow will mostly be used in Python scripts, rather than notebooks, where this will not be a problem if everything is kept in the same TensorFlow strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 17:37:02.905241: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-07-03 17:37:03.075118: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fd570055fc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-03 17:37:03.075170: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
      "2024-07-03 17:37:03.081754: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-03 17:37:03.126585: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2024-07-03 17:37:03.319370: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "INFO:root:Loading event times from cache.\n",
      "2024-07-03 17:37:11.560759: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: No function library is provided.\n",
      "\t [[{{node PartitionedCall_1}}]]\n",
      "2024-07-03 17:37:11.561178: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: No function library is provided.\n",
      "\t [[{{node PartitionedCall_2}}]]\n",
      "2024-07-03 17:37:11.567823: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: No function library is provided.\n",
      "\t [[{{node PartitionedCall_1}}]]\n",
      "2024-07-03 17:37:11.568164: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: No function library is provided.\n",
      "\t [[{{node PartitionedCall_2}}]]\n",
      "2024-07-03 17:37:11.598433: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: No function library is provided.\n",
      "\t [[{{node PartitionedCall_1}}]]\n",
      "2024-07-03 17:37:11.598767: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: No function library is provided.\n",
      "\t [[{{node PartitionedCall_2}}]]\n",
      "2024-07-03 17:37:11.599350: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: No function library is provided.\n",
      "\t [[{{node PartitionedCall_1}}]]\n",
      "2024-07-03 17:37:11.599664: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: No function library is provided.\n",
      "\t [[{{node PartitionedCall_2}}]]\n",
      "2024-07-03 17:37:11.616432: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: No function library is provided.\n",
      "\t [[{{function_node __inference_snr_1250}}{{node PartitionedCall_2}}]]\n",
      "2024-07-03 17:37:11.623132: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: No function library is provided.\n",
      "\t [[{{function_node __inference_psd_1124}}{{node PartitionedCall}}]]\n",
      "2024-07-03 17:37:13.050002: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'background' with dtype float and shape [?,1,32768]\n",
      "\t [[{{node background}}]]\n",
      "2024-07-03 17:37:14.281447: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'fir' with dtype float and shape [?,?,4096]\n",
      "\t [[{{node fir}}]]\n",
      "2024-07-03 17:37:14.299875: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'timeseries' with dtype float and shape [?,1,4096]\n",
      "\t [[{{node timeseries}}]]\n",
      "2024-07-03 17:37:14.331773: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1,4096]\n",
      "\t [[{{node inputs}}]]\n",
      "2024-07-03 17:37:14.331909: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_1' with dtype float and shape [?,1,32768]\n",
      "\t [[{{node inputs_1}}]]\n",
      "2024-07-03 17:37:14.459165: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [?,1,4096]\n",
      "\t [[{{node Placeholder}}]]\n",
      "2024-07-03 17:37:14.459290: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [?,1,32768]\n",
      "\t [[{{node Placeholder_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " ONSOURCE (InputLayer)          [(None, 1, 4096)]    0           []                               \n",
      "                                                                                                  \n",
      " OFFSOURCE (InputLayer)         [(None, 1, 32768)]   0           []                               \n",
      "                                                                                                  \n",
      " whiten (Whiten)                (None, 1, 2048)      0           ['ONSOURCE[0][0]',               \n",
      "                                                                  'OFFSOURCE[0][0]']              \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 2048, 1)      0           ['whiten[0][0]']                 \n",
      "                                                                                                  \n",
      " Convolutional_1 (Conv1D)       (None, 2048, 8)      520         ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " ELU_1 (ELU)                    (None, 2048, 8)      0           ['Convolutional_1[0][0]']        \n",
      "                                                                                                  \n",
      " Pooling_1 (MaxPooling1D)       (None, 512, 8)       0           ['ELU_1[0][0]']                  \n",
      "                                                                                                  \n",
      " Convolutional_2 (Conv1D)       (None, 512, 8)       2056        ['Pooling_1[0][0]']              \n",
      "                                                                                                  \n",
      " ELU_2 (ELU)                    (None, 512, 8)       0           ['Convolutional_2[0][0]']        \n",
      "                                                                                                  \n",
      " Convolutional_3 (Conv1D)       (None, 512, 16)      4112        ['ELU_2[0][0]']                  \n",
      "                                                                                                  \n",
      " ELU_3 (ELU)                    (None, 512, 16)      0           ['Convolutional_3[0][0]']        \n",
      "                                                                                                  \n",
      " Pooling_3 (MaxPooling1D)       (None, 128, 16)      0           ['ELU_3[0][0]']                  \n",
      "                                                                                                  \n",
      " Flatten (Flatten)              (None, 2048)         0           ['Pooling_3[0][0]']              \n",
      "                                                                                                  \n",
      " Dense_1 (Dense)                (None, 64)           131136      ['Flatten[0][0]']                \n",
      "                                                                                                  \n",
      " ELU_7 (ELU)                    (None, 64)           0           ['Dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " Dropout_1 (Dropout)            (None, 64)           0           ['ELU_7[0][0]']                  \n",
      "                                                                                                  \n",
      " Dense_2 (Dense)                (None, 64)           4160        ['Dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " ELU_8 (ELU)                    (None, 64)           0           ['Dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " Dropout_2 (Dropout)            (None, 64)           0           ['ELU_8[0][0]']                  \n",
      "                                                                                                  \n",
      " INJECTION_MASKS (Dense)        (None, 1)            65          ['Dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 142,049\n",
      "Trainable params: 142,049\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with env:\n",
    "    # This object will be used to obtain real interferometer data based on specified parameters.\n",
    "    ifo_data_obtainer : gf.IFODataObtainer = gf.IFODataObtainer(\n",
    "        observing_runs=gf.ObservingRun.O3, # Specify the observing run (e.g., O3).\n",
    "        data_quality=gf.DataQuality.BEST,  # Choose the quality of the data (e.g., BEST).\n",
    "        data_labels=[                      # Define the types of data to include.\n",
    "            gf.DataLabel.NOISE, \n",
    "            gf.DataLabel.GLITCHES\n",
    "        ],\n",
    "        segment_order=gf.SegmentOrder.RANDOM, # Order of segment retrieval (e.g., RANDOM).\n",
    "        force_acquisition=True,               # Force the acquisition of new data.\n",
    "        cache_segments=False                  # Choose not to cache the segments.\n",
    "    )\n",
    "\n",
    "    # Initialize the noise generator wrapper:\n",
    "    # This wrapper will use the ifo_data_obtainer to generate real noise based on the specified parameters.\n",
    "    noise: gf.NoiseObtainer = gf.NoiseObtainer(\n",
    "        ifo_data_obtainer=ifo_data_obtainer, # Use the previously set up IFODataObtainer object.\n",
    "        noise_type=gf.NoiseType.REAL,        # Specify the type of noise as REAL.\n",
    "        ifos=gf.IFO.L1                       # Specify the interferometer (e.g., LIGO Livingston L1).\n",
    "    )\n",
    "\n",
    "    scaling_method : gf.ScalingMethod = gf.ScalingMethod(\n",
    "        value=gf.Distribution(\n",
    "            min_=8.0,\n",
    "            max_=15.0,\n",
    "            type_=gf.DistributionType.UNIFORM\n",
    "        ),\n",
    "        type_=gf.ScalingTypes.SNR\n",
    "    )\n",
    "\n",
    "    # Define a uniform distribution for the mass of the first object in solar masses.\n",
    "    mass_1_distribution_msun : gf.Distribution = gf.Distribution(\n",
    "        min_=10.0, \n",
    "        max_=60.0, \n",
    "        type_=gf.DistributionType.UNIFORM\n",
    "    )\n",
    "\n",
    "    # Define a uniform distribution for the mass of the second object in solar masses.\n",
    "    mass_2_distribution_msun : gf.Distribution = gf.Distribution(\n",
    "        min_=10.0, \n",
    "        max_=60.0, \n",
    "        type_=gf.DistributionType.UNIFORM\n",
    "    )\n",
    "\n",
    "    # Define a uniform distribution for the inclination of the binary system in radians.\n",
    "    inclination_distribution_radians : gf.Distribution = gf.Distribution(\n",
    "        min_=0.0, \n",
    "        max_=np.pi, \n",
    "        type_=gf.DistributionType.UNIFORM\n",
    "    )\n",
    "\n",
    "    # Initialize a PhenomD waveform generator with the defined distributions.\n",
    "    # This generator will produce waveforms with randomly varied masses and inclination angles.\n",
    "    phenom_d_generator : gf.WaveformGenerator = gf.cuPhenomDGenerator(\n",
    "        mass_1_msun=mass_1_distribution_msun,\n",
    "        mass_2_msun=mass_2_distribution_msun,\n",
    "        inclination_radians=inclination_distribution_radians,\n",
    "        scaling_method=scaling_method,\n",
    "        injection_chance=0.5 # Set so half produced examples will not contain this signal\n",
    "    )\n",
    "    \n",
    "    training_dataset : tf.data.Dataset = gf.Dataset(       \n",
    "        noise_obtainer=noise,\n",
    "        waveform_generators=phenom_d_generator,\n",
    "        input_variables=[\n",
    "            gf.ReturnVariables.ONSOURCE, \n",
    "            gf.ReturnVariables.OFFSOURCE, \n",
    "        ],\n",
    "        output_variables=[\n",
    "            gf.ReturnVariables.INJECTION_MASKS\n",
    "        ]\n",
    "    ).map(adjust_features)\n",
    "\n",
    "    validation_dataset : tf.data.Dataset = gf.Dataset(       \n",
    "        noise_obtainer=noise,\n",
    "        waveform_generators=phenom_d_generator,\n",
    "        seed=1001, # Implement different seed to generate different waveforms,\n",
    "        group=\"validate\", # Ensure noise is pulled from those marked for validation.\n",
    "        input_variables=[\n",
    "            gf.ReturnVariables.ONSOURCE, \n",
    "            gf.ReturnVariables.OFFSOURCE, \n",
    "        ],\n",
    "        output_variables=[\n",
    "            gf.ReturnVariables.INJECTION_MASKS\n",
    "        ]\n",
    "    ).map(adjust_features)\n",
    "\n",
    "    testing_dataset : tf.data.Dataset = gf.Dataset(       \n",
    "        noise_obtainer=noise,\n",
    "        waveform_generators=phenom_d_generator,\n",
    "        seed=1002, # Implement different seed to generate different waveforms,\n",
    "        group=\"test\", # Ensure noise is pulled from those marked for validation.\n",
    "        input_variables=[\n",
    "            gf.ReturnVariables.ONSOURCE, \n",
    "            gf.ReturnVariables.OFFSOURCE, \n",
    "        ],\n",
    "        output_variables=[\n",
    "            gf.ReturnVariables.INJECTION_MASKS\n",
    "        ]\n",
    "    ).map(adjust_features)\n",
    "    \n",
    "    for input_example, _ in training_dataset.take(1):\n",
    "        input_shape_onsource = input_example[\"ONSOURCE\"].shape[1:]  # Exclude batch dimension    \n",
    "        input_shape_offsource = input_example[\"OFFSOURCE\"].shape[1:] \n",
    "\n",
    "    model = create_gabbard(input_shape_onsource, input_shape_offsource)\n",
    "\n",
    "    # Now you can print the model summary\n",
    "    model.summary()\n",
    "    \n",
    "    # Model compilation\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',  # Or any other loss function appropriate for your task\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the previous cell failed it is most likely because you attempted to run it twice within the same kernel session. The kernal must be restarted in order to generate a fresh TensorFlow stratergy and recompile the model.\n",
    "\n",
    "Finally, we can train the model with our generated dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 17:37:17.876655: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-07-03 17:37:17.900528: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-07-03 17:37:20.857489: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: No function library is provided.\n",
      "\t [[{{function_node __inference_psd_2444}}{{node PartitionedCall}}]]\n",
      "2024-07-03 17:37:20.867891: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: No function library is provided.\n",
      "\t [[{{function_node __inference_truncate_transfer_2578}}{{node PartitionedCall}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - ETA: 0s - loss: 0.1611 - accuracy: 0.9381"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 17:38:04.944023: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-07-03 17:38:04.971221: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "examples_per_epoch : int = int(1E5)\n",
    "num_validation_examples : int = int(1E4)\n",
    "num_testing_examples : int = int(1E4)\n",
    "with env: \n",
    "    history = model.fit(\n",
    "        training_dataset,\n",
    "        epochs=10,  # Number of epochs to train for\n",
    "        steps_per_epoch=examples_per_epoch // gf.Defaults.num_examples_per_batch,\n",
    "        validation_data=validation_dataset,\n",
    "        validation_steps=num_validation_examples // gf.Defaults.num_examples_per_batch #Ensure this is set as dataset is uncapped\n",
    "    )\n",
    "\n",
    "    model.evaluate(\n",
    "        testing_dataset, \n",
    "        steps=num_testing_examples // gf.Defaults.num_examples_per_batch\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('gravyflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0be68b4d857a3b55dcb84670c9ea8054a433650dc9da871ef592f2f480116ffb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
