{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5: Composing Datasets\n",
    "\n",
    "In this notebook we will examine how we can use the elements we have encountered so far, in order to construct a TensorFlow dataset which will allow us to train machine learning models with data generated in real time. This is the core and most usefull functionality of the dataset portion of GravyFlow.\n",
    "\n",
    "As usual, we begin by performing the relevent imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 10:45:23.060816: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-29 10:45:23.060858: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-29 10:45:23.062061: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-29 10:45:23.069452: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-29 10:45:24.478182: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Built-in imports\n",
    "from typing import List, Dict\n",
    "from pathlib import Path\n",
    "\n",
    "# Dependency imports: \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Dense, Flatten, Dropout, ELU\n",
    "from tensorflow.keras.models import Model\n",
    "from bokeh.io import show, output_notebook\n",
    "from bokeh.layouts import gridplot\n",
    "\n",
    "# Import the GravyFlow module.\n",
    "import gravyflow as gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:TensorFlow version: 2.15.0, CUDA version: 12.2\n",
      "2024-02-29 10:45:47.509205: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-02-29 10:45:47.509473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2000 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:06:00.0, compute capability: 7.0\n",
      "INFO:root:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "env = gf.env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_features(features, labels):\n",
    "    labels['INJECTION_MASKS'] = labels['INJECTION_MASKS'][0]\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gabbard_model(\n",
    "        input_shape_onsource : int, \n",
    "        input_shape_offsource : int\n",
    "    ) -> tf.keras.Model:\n",
    "    \n",
    "    # Define the inputs based on the dictionary keys and expected shapes\n",
    "    # Replace `input_shape_onsource` and `input_shape_offsource` with the actual shapes\n",
    "    onsource_input = Input(shape=input_shape_onsource, name=\"ONSOURCE\")\n",
    "    offsource_input = Input(shape=input_shape_offsource, name=\"OFFSOURCE\")\n",
    "\n",
    "    # Pass the inputs to your custom Whiten layer\n",
    "    # Assuming your Whiten layer can handle multiple inputs\n",
    "    whiten_output = gf.Whiten()([onsource_input, offsource_input])\n",
    "\n",
    "    x = gf.Reshape()(whiten_output)\n",
    "    \n",
    "    # Convolutional and Pooling layers\n",
    "    x = Conv1D(8, 64, padding='same', name=\"Convolutional_1\")(x)\n",
    "    x = ELU(name=\"ELU_1\")(x)\n",
    "    x = MaxPooling1D(pool_size=4, strides=4, name=\"Pooling_1\", padding=\"same\")(x)\n",
    "    \n",
    "    x = Conv1D(8, 32, padding='same', name=\"Convolutional_2\")(x)\n",
    "    x = ELU(name=\"ELU_2\")(x)\n",
    "    x = Conv1D(16, 32, padding='same', name=\"Convolutional_3\")(x)\n",
    "    x = ELU(name=\"ELU_3\")(x)\n",
    "    x = MaxPooling1D(pool_size=4, strides=4, name=\"Pooling_3\", padding=\"same\")(x)\n",
    "\n",
    "    x = Conv1D(16, 16, padding='same', name=\"Convolutional_4\")(x)\n",
    "    x = ELU(name=\"ELU_4\")(x)\n",
    "    x = Conv1D(32, 16, padding='same', name=\"Convolutional_5\")(x)\n",
    "    x = ELU(name=\"ELU_5\")(x)\n",
    "    x = MaxPooling1D(pool_size=4, strides=4, name=\"Pooling_5\", padding=\"same\")(x)\n",
    "    \n",
    "    x = Conv1D(32, 16, padding='same', name=\"Convolutional_6\")(x)\n",
    "    x = ELU(name=\"ELU_6\")(x)\n",
    "    \n",
    "    # Flatten layer\n",
    "    x = Flatten(name=\"Flatten\")(x)\n",
    "    \n",
    "    # Dense layers with dropout\n",
    "    x = Dense(64, name=\"Dense_1\")(x)\n",
    "    x = ELU(name=\"ELU_7\")(x)\n",
    "    x = Dropout(0.5, name=\"Dropout_1\")(x)\n",
    "    \n",
    "    x = Dense(64, name=\"Dense_2\")(x)\n",
    "    x = ELU(name=\"ELU_8\")(x)\n",
    "    x = Dropout(0.5, name=\"Dropout_2\")(x)\n",
    "    \n",
    "    outputs = Dense(1, activation='sigmoid', name=\"INJECTION_MASKS\")(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs=[onsource_input, offsource_input], outputs=outputs, name=\"custom_model\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 10:45:48.424549: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fa8e4034b20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-29 10:45:48.424576: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
      "2024-02-29 10:45:48.429837: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-02-29 10:45:48.472450: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-02-29 10:45:48.527117: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1709232348.587994  834282 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "/home/michael.norman/miniconda3/envs/gravyflow/lib/python3.10/site-packages/igwn_auth_utils/x509.py:98: CryptographyDeprecationWarning: Properties that return a naïve datetime object have been deprecated. Please switch to not_valid_after_utc.\n",
      "  return (cert.not_valid_after - datetime.utcnow()).total_seconds()\n",
      "/home/michael.norman/miniconda3/envs/gravyflow/lib/python3.10/site-packages/igwn_auth_utils/x509.py:98: CryptographyDeprecationWarning: Properties that return a naïve datetime object have been deprecated. Please switch to not_valid_after_utc.\n",
      "  return (cert.not_valid_after - datetime.utcnow()).total_seconds()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " ONSOURCE (InputLayer)       [(None, 1, 4096)]            0         []                            \n",
      "                                                                                                  \n",
      " OFFSOURCE (InputLayer)      [(None, 1, 32768)]           0         []                            \n",
      "                                                                                                  \n",
      " whiten (Whiten)             (None, 1, 2048)              0         ['ONSOURCE[0][0]',            \n",
      "                                                                     'OFFSOURCE[0][0]']           \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 2048, 1)              0         ['whiten[0][0]']              \n",
      "                                                                                                  \n",
      " Convolutional_1 (Conv1D)    (None, 2048, 8)              520       ['reshape[0][0]']             \n",
      "                                                                                                  \n",
      " ELU_1 (ELU)                 (None, 2048, 8)              0         ['Convolutional_1[0][0]']     \n",
      "                                                                                                  \n",
      " Pooling_1 (MaxPooling1D)    (None, 512, 8)               0         ['ELU_1[0][0]']               \n",
      "                                                                                                  \n",
      " Convolutional_2 (Conv1D)    (None, 512, 8)               2056      ['Pooling_1[0][0]']           \n",
      "                                                                                                  \n",
      " ELU_2 (ELU)                 (None, 512, 8)               0         ['Convolutional_2[0][0]']     \n",
      "                                                                                                  \n",
      " Convolutional_3 (Conv1D)    (None, 512, 16)              4112      ['ELU_2[0][0]']               \n",
      "                                                                                                  \n",
      " ELU_3 (ELU)                 (None, 512, 16)              0         ['Convolutional_3[0][0]']     \n",
      "                                                                                                  \n",
      " Pooling_3 (MaxPooling1D)    (None, 128, 16)              0         ['ELU_3[0][0]']               \n",
      "                                                                                                  \n",
      " Convolutional_4 (Conv1D)    (None, 128, 16)              4112      ['Pooling_3[0][0]']           \n",
      "                                                                                                  \n",
      " ELU_4 (ELU)                 (None, 128, 16)              0         ['Convolutional_4[0][0]']     \n",
      "                                                                                                  \n",
      " Convolutional_5 (Conv1D)    (None, 128, 32)              8224      ['ELU_4[0][0]']               \n",
      "                                                                                                  \n",
      " ELU_5 (ELU)                 (None, 128, 32)              0         ['Convolutional_5[0][0]']     \n",
      "                                                                                                  \n",
      " Pooling_5 (MaxPooling1D)    (None, 32, 32)               0         ['ELU_5[0][0]']               \n",
      "                                                                                                  \n",
      " Convolutional_6 (Conv1D)    (None, 32, 32)               16416     ['Pooling_5[0][0]']           \n",
      "                                                                                                  \n",
      " ELU_6 (ELU)                 (None, 32, 32)               0         ['Convolutional_6[0][0]']     \n",
      "                                                                                                  \n",
      " Flatten (Flatten)           (None, 1024)                 0         ['ELU_6[0][0]']               \n",
      "                                                                                                  \n",
      " Dense_1 (Dense)             (None, 64)                   65600     ['Flatten[0][0]']             \n",
      "                                                                                                  \n",
      " ELU_7 (ELU)                 (None, 64)                   0         ['Dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " Dropout_1 (Dropout)         (None, 64)                   0         ['ELU_7[0][0]']               \n",
      "                                                                                                  \n",
      " Dense_2 (Dense)             (None, 64)                   4160      ['Dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " ELU_8 (ELU)                 (None, 64)                   0         ['Dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " Dropout_2 (Dropout)         (None, 64)                   0         ['ELU_8[0][0]']               \n",
      "                                                                                                  \n",
      " INJECTION_MASKS (Dense)     (None, 1)                    65        ['Dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 105265 (411.19 KB)\n",
      "Trainable params: 105265 (411.19 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with env:\n",
    "    # This object will be used to obtain real interferometer data based on specified parameters.\n",
    "    ifo_data_obtainer : gf.IFODataObtainer = gf.IFODataObtainer(\n",
    "        observing_runs=gf.ObservingRun.O3, # Specify the observing run (e.g., O3).\n",
    "        data_quality=gf.DataQuality.BEST,  # Choose the quality of the data (e.g., BEST).\n",
    "        data_labels=[                      # Define the types of data to include.\n",
    "            gf.DataLabel.NOISE, \n",
    "            gf.DataLabel.GLITCHES\n",
    "        ],\n",
    "        segment_order=gf.SegmentOrder.RANDOM, # Order of segment retrieval (e.g., RANDOM).\n",
    "        force_acquisition=True,               # Force the acquisition of new data.\n",
    "        cache_segments=False                  # Choose not to cache the segments.\n",
    "    )\n",
    "\n",
    "    # Initialize the noise generator wrapper:\n",
    "    # This wrapper will use the ifo_data_obtainer to generate real noise based on the specified parameters.\n",
    "    noise: gf.NoiseObtainer = gf.NoiseObtainer(\n",
    "        ifo_data_obtainer=ifo_data_obtainer, # Use the previously set up IFODataObtainer object.\n",
    "        noise_type=gf.NoiseType.REAL,        # Specify the type of noise as REAL.\n",
    "        ifos=gf.IFO.L1                       # Specify the interferometer (e.g., LIGO Livingston L1).\n",
    "    )\n",
    "\n",
    "    scaling_method : gf.ScalingMethod = gf.ScalingMethod(\n",
    "        value=gf.Distribution(\n",
    "            min_=8.0,\n",
    "            max_=15.0,\n",
    "            type_=gf.DistributionType.UNIFORM\n",
    "        ),\n",
    "        type_=gf.ScalingTypes.SNR\n",
    "    )\n",
    "\n",
    "    # Define a uniform distribution for the mass of the first object in solar masses.\n",
    "    mass_1_distribution_msun : gf.Distribution = gf.Distribution(\n",
    "        min_=10.0, \n",
    "        max_=60.0, \n",
    "        type_=gf.DistributionType.UNIFORM\n",
    "    )\n",
    "\n",
    "    # Define a uniform distribution for the mass of the second object in solar masses.\n",
    "    mass_2_distribution_msun : gf.Distribution = gf.Distribution(\n",
    "        min_=10.0, \n",
    "        max_=60.0, \n",
    "        type_=gf.DistributionType.UNIFORM\n",
    "    )\n",
    "\n",
    "    # Define a uniform distribution for the inclination of the binary system in radians.\n",
    "    inclination_distribution_radians : gf.Distribution = gf.Distribution(\n",
    "        min_=0.0, \n",
    "        max_=np.pi, \n",
    "        type_=gf.DistributionType.UNIFORM\n",
    "    )\n",
    "\n",
    "    # Initialize a PhenomD waveform generator with the defined distributions.\n",
    "    # This generator will produce waveforms with randomly varied masses and inclination angles.\n",
    "    phenom_d_generator : gf.WaveformGenerator = gf.cuPhenomDGenerator(\n",
    "        mass_1_msun=mass_1_distribution_msun,\n",
    "        mass_2_msun=mass_2_distribution_msun,\n",
    "        inclination_radians=inclination_distribution_radians,\n",
    "        scaling_method=scaling_method,\n",
    "        injection_chance=0.5 # Set so half produced examples will not contain this signal\n",
    "    )\n",
    "    \n",
    "    dataset : tf.data.Dataset = gf.Dataset(       \n",
    "        noise_obtainer=noise,\n",
    "        waveform_generators=phenom_d_generator,\n",
    "        input_variables=[\n",
    "            gf.ReturnVariables.ONSOURCE, \n",
    "            gf.ReturnVariables.OFFSOURCE, \n",
    "        ],\n",
    "        output_variables=[\n",
    "            gf.ReturnVariables.INJECTION_MASKS\n",
    "        ]\n",
    "    ).map(adjust_features)\n",
    "    \n",
    "    for input_example, _ in dataset.take(1):\n",
    "        input_shape_onsource = input_example[\"ONSOURCE\"].shape[1:]  # Exclude batch dimension    \n",
    "        input_shape_offsource = input_example[\"OFFSOURCE\"].shape[1:] \n",
    "\n",
    "    model = create_gabbard_model(input_shape_onsource, input_shape_offsource)\n",
    "\n",
    "    # Now you can print the model summary\n",
    "    model.summary()\n",
    "    \n",
    "    # Model compilation\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',  # Or any other loss function appropriate for your task\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael.norman/miniconda3/envs/gravyflow/lib/python3.10/site-packages/igwn_auth_utils/x509.py:98: CryptographyDeprecationWarning: Properties that return a naïve datetime object have been deprecated. Please switch to not_valid_after_utc.\n",
      "  return (cert.not_valid_after - datetime.utcnow()).total_seconds()\n",
      "2024-02-29 10:46:12.075722: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 15s 22ms/step - loss: 0.2001 - accuracy: 0.9200\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 6s 65ms/step - loss: 0.0582 - accuracy: 0.9822\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 9s 86ms/step - loss: 0.0720 - accuracy: 0.9841\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 0.0834 - accuracy: 0.9750\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 8s 76ms/step - loss: 0.0525 - accuracy: 0.9853\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 5s 51ms/step - loss: 0.0226 - accuracy: 0.9941\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0535 - accuracy: 0.9866\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 6s 59ms/step - loss: 0.0399 - accuracy: 0.9894\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 0.0532 - accuracy: 0.9866\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 0.0436 - accuracy: 0.9866\n"
     ]
    }
   ],
   "source": [
    "with env: \n",
    "    history = model.fit(\n",
    "        dataset,\n",
    "        epochs=10,  # Number of epochs to train for\n",
    "        steps_per_epoch=100 /gf.Defaults.num_examples_per_batch\n",
    "        #validation_data=validation_dataset  # Assuming you have a validation dataset\n",
    "        # Add other parameters as needed, such as callbacks\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('gravyflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0be68b4d857a3b55dcb84670c9ea8054a433650dc9da871ef592f2f480116ffb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
